{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e15554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:34:05.184149: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 23:34:05.921161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4df0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/vladt/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "'Concrete Crack Images for Classification.rar'\t model_image.png\r\n",
      " concrete_images\t\t\t\t Roads.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66649ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'concrete_images'\n",
    "batch_size = 8\n",
    "target_size = (120, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5027cdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32000 images belonging to 2 classes.\n",
      "Found 8000 images belonging to 2 classes.\n",
      "Found 40000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1./255,  # Масштабирование пикселей\n",
    "    shear_range=0.2,  # Параметры аугментации\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Разделение на обучающую и валидационную выборки\n",
    ")\n",
    "\n",
    "train_data = image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=dataset_path,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=target_size, \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_data = image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=dataset_path,\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=target_size, \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical')\n",
    "test_data = image_generator.flow_from_directory(\n",
    "    dataset_path,  # Путь к папке с тестовыми изображениями\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # режим классификации (для многоклассовой классификации)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602f7484",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 17\u001b[0m\n\u001b[1;32m      7\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mImageDataGenerator(\n\u001b[1;32m      8\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,  \u001b[38;5;66;03m# Масштабирование пикселей\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Параметры аугментации\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39mtrain_split  \u001b[38;5;66;03m# Разделение на обучающую и валидационную выборки\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Загрузка данных для обучения с использованием генератора\u001b[39;00m\n\u001b[1;32m     16\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mtrain_dir\u001b[49m,\n\u001b[1;32m     18\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_height, img_width),\n\u001b[1;32m     19\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     20\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# режим классификации (для многоклассовой классификации)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# указание на использование обучающей выборки\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Загрузка данных для валидации с использованием генератора\u001b[39;00m\n\u001b[1;32m     25\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     26\u001b[0m     train_dir,\n\u001b[1;32m     27\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_height, img_width),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# указание на использование валидационной выборки\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# batch_size = 32\n",
    "# img_height = 224\n",
    "# img_width = 224\n",
    "# train_split = 0.8  # Процент данных, используемых для обучения\n",
    "\n",
    "# # Создание генератора данных для обучения\n",
    "# train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     rescale=1./255,  # Масштабирование пикселей\n",
    "#     shear_range=0.2,  # Параметры аугментации\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=train_split  # Разделение на обучающую и валидационную выборки\n",
    "# )\n",
    "\n",
    "# # Загрузка данных для обучения с использованием генератора\n",
    "# train_dataset = train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',  # режим классификации (для многоклассовой классификации)\n",
    "#     subset='training'  # указание на использование обучающей выборки\n",
    "# )\n",
    "\n",
    "# # Загрузка данных для валидации с использованием генератора\n",
    "# validation_dataset = train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',  # режим классификации (для многоклассовой классификации)\n",
    "#     subset='validation'  # указание на использование валидационной выборки\n",
    "# )\n",
    "\n",
    "# # Создание тестовой выборки без аугментации данных\n",
    "# test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     rescale=1./255  # Масштабирование пикселей\n",
    "# )\n",
    "\n",
    "# # Загрузка тестовой выборки с использованием генератора\n",
    "# test_dataset = test_datagen.flow_from_directory(\n",
    "#     test_dir,  # Путь к папке с тестовыми изображениями\n",
    "#     target_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical'  # режим классификации (для многоклассовой классификации)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce5b70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 120, 120, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 60, 60, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,176\n",
      "Trainable params: 130,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 120, 120, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 60, 60, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                200768    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:34:15.869010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:15.892381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:15.892617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:15.893707: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:15.893914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:15.894079: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:16.460108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:16.460326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:16.460492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 23:34:16.460611: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-04-16 23:34:16.460676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4195 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331,074\n",
      "Trainable params: 331,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:34:16.939385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-16 23:34:18.413598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-16 23:34:19.078175: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f781401bb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-16 23:34:19.078226: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2023-04-16 23:34:19.088654: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-16 23:34:19.286328: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999/4000 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:36:10.934784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 140s 34ms/step - loss: 0.1007 - accuracy: 0.9591 - val_loss: 0.0189 - val_accuracy: 0.9935\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 141s 35ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 0.0323 - val_accuracy: 0.9898\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 144s 36ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0083 - val_accuracy: 0.9970\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 153s 38ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 159s 40ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "   4/1000 [..............................] - ETA: 35s - loss: 0.0012 - accuracy: 1.0000    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:46:34.423845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 840/1000 [========================>.....] - ETA: 4s - loss: 0.0046 - accuracy: 0.9984"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation='relu', input_shape=(120, 120, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "# вывод информации о модели\n",
    "model.summary()\n",
    "## Добавление полносвязных слоев\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "# визуализация построенной модели\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_image.png', show_layer_names=False, show_shapes=True)\n",
    "## Компиляция и обучение модели\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "### Обучение модели\n",
    "history = model.fit(train_data, validation_data = validation_data, batch_size=batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ls, acc) = model.evaluate(test_data)\n",
    "print('Точность модели = {} %'.format(acc * 100), '. Величина ошибки = {} %'.format(ls * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01743f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('roads.ht5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
